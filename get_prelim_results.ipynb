{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from random import sample, choice\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_max(df):\n",
    "    df1 = df.drop('dataset', axis=1)\n",
    "    maxes = {}      # {dataset: [max1, max2, ...]}\n",
    "    for i in range(df.shape[0]):\n",
    "        row = np.array(df1.iloc[i])\n",
    "        row_maxes = np.argwhere(row == np.amax(row)).flatten().tolist()\n",
    "        maxes[df.iloc[i, 0]] = row_maxes\n",
    "        # maxes[df.iloc[i, 0]] = df1.columns[row_maxes].tolist() # if you want col names\n",
    "    return maxes\n",
    "\n",
    "pre = pd.read_csv(\"/users/guest/j/jhiggin6/Documents/Thesis/emp_results.csv\")\n",
    "pre['dataset'] = pre['dataset'].apply(lambda x: int(re.split(r'\\.arff', x)[0]))\n",
    "\n",
    "optimized_cols = []\n",
    "default_cols = []\n",
    "\n",
    "for col in pre.columns:\n",
    "    if col == 'dataset':\n",
    "        optimized_cols.append(col)\n",
    "        default_cols.append(col)\n",
    "    if \"+\" in col:\n",
    "        optimized_cols.append(col)\n",
    "    elif \"-\" in col:\n",
    "        default_cols.append(col)\n",
    "\n",
    "optim_maxes = multiple_max(pre[optimized_cols])\n",
    "default_maxes = multiple_max(pre[default_cols])\n",
    "\n",
    "# optim_maxes = {dataset: [max1, max2, ..., max466]}\n",
    "# default_maxes = {dataset: [max1, max2, ..., max466]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_meta_model(sk_algorithm, iters, X, y, valid_datasets, maxes):\n",
    "    accuracies = []\n",
    "    for i in range(iters):\n",
    "        X_train, X_test, y_train, y_test, ds_train, ds_test = train_test_split(X, y, valid_datasets,\n",
    "                                                        test_size=0.33, stratify=y)\n",
    "        model = sk_algorithm\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        correct = 0\n",
    "        for ds, prediction in zip(ds_test, y_pred):\n",
    "            if prediction in maxes[ds]:\n",
    "                correct += 1\n",
    "        accuracies.append(correct/len(ds_test))\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: concept_metadataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:   8%|▊         | 1/13 [17:42<3:32:26, 1062.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: clustering_metadataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:  15%|█▌        | 2/13 [41:36<3:54:53, 1281.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: all_metadataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:  23%|██▎       | 3/13 [2:30:12<10:11:54, 3671.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: general_metadataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:  31%|███       | 4/13 [2:52:26<6:52:16, 2748.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: model-based_metadataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:  38%|███▊      | 5/13 [3:23:26<5:23:46, 2428.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: landmarking_metadataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:  46%|████▌     | 6/13 [3:52:17<4:15:37, 2191.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: itemset_metadataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:  54%|█████▍    | 7/13 [4:11:55<3:06:00, 1860.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: complexity_metadataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:  62%|██████▏   | 8/13 [4:46:19<2:40:24, 1924.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: info-theory_metadataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:  69%|██████▉   | 9/13 [5:15:20<2:04:29, 1867.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: d2v_pretrained_metadaset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:  77%|███████▋  | 10/13 [5:54:10<1:40:30, 2010.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: default_metadataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:  85%|████████▍ | 11/13 [7:19:08<1:38:30, 2955.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: statistical_metadataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets:  92%|█████████▏| 12/13 [8:05:20<48:19, 2899.63s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_name: relative_metadataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-datasets: 100%|██████████| 13/13 [8:28:28<00:00, 2346.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# Variables for meta-model\n",
    "models = [\"Metadataset\", \"RandomForest\", \"LogisticRegression\", \"SVC\", \"KNeighbors\",\n",
    "          \"GaussianNB\", \"DecisionTree\", \"AdaBoost\", \"GradientBoosting\",\n",
    "          \"MLP\", \"Bagging\", \"ExtraTrees\",  \"Voting\"]\n",
    "results = []\n",
    "maxes = optim_maxes\n",
    "iters = 1000\n",
    "\n",
    "meta_datasets_path = \"/users/guest/j/jhiggin6/Documents/Thesis/meta_datasets\"\n",
    "meta_datasets = {}\n",
    "for meta_dataset in os.listdir(meta_datasets_path):\n",
    "    meta_datasets[meta_dataset] = pd.read_csv(os.path.join(meta_datasets_path, meta_dataset))\n",
    "\n",
    "for df_name, df in tqdm(meta_datasets.items(), desc=\"Meta-datasets\"):\n",
    "    # df_name, df = choice(list(meta_datasets.items()))\n",
    "    print('df_name:', df_name)\n",
    "    results_arr = [df_name]\n",
    "    X = []\n",
    "    y = []\n",
    "    valid_datasets = []\n",
    "\n",
    "    # df_name, df = choice(list(meta_datasets.items()))\n",
    "    df.replace(np.nan, 0, inplace=True)\n",
    "    df.replace(np.inf, 0, inplace=True)\n",
    "    # print('metadataset:', df_name)\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.loc[i, 'dataset'] in maxes:\n",
    "            y.append(sample(maxes[df.loc[i, 'dataset']],k=1)[0])\n",
    "            X.append(df.iloc[i, 1:].tolist())\n",
    "            valid_datasets.append(df.loc[i, 'dataset'])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "    rf_accuracies = train_meta_model(rf, iters, X, y, valid_datasets, maxes)\n",
    "    results_arr.append(np.mean(rf_accuracies))\n",
    "    # print(f'rf accuracy: {round(np.mean(rf_accuracies)*100,2)}%', flush=True)\n",
    "\n",
    "    # Logistic Regression\n",
    "    lr = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "    lr_accuracies = train_meta_model(lr, iters, X, y, valid_datasets, maxes)\n",
    "    results_arr.append(np.mean(lr_accuracies))\n",
    "    # print(f'lr accuracy: {round(np.mean(lr_accuracies)*100,2)}%', flush=True)\n",
    "\n",
    "    # SVM\n",
    "    svm = SVC(gamma='auto')\n",
    "    svm_accuracies = train_meta_model(svm, iters, X, y, valid_datasets, maxes)\n",
    "    results_arr.append(np.mean(svm_accuracies))\n",
    "    # print(f'svm accuracy: {round(np.mean(svm_accuracies)*100,2)}%', flush=True)\n",
    "\n",
    "    # KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn_accuracies = train_meta_model(knn, iters, X, y, valid_datasets, maxes)\n",
    "    results_arr.append(np.mean(knn_accuracies))\n",
    "    # print(f'knn accuracy: {round(np.mean(knn_accuracies)*100,2)}%', flush=True)\n",
    "\n",
    "    # Naive Bayes\n",
    "    nb = GaussianNB()\n",
    "    nb_accuracies = train_meta_model(nb, iters, X, y, valid_datasets, maxes)\n",
    "    results_arr.append(np.mean(nb_accuracies))\n",
    "    # print(f'nb accuracy: {round(np.mean(nb_accuracies)*100,2)}%')\n",
    "\n",
    "    # Decision Tree\n",
    "    dt = DecisionTreeClassifier(random_state=0)\n",
    "    dt_accuracies = train_meta_model(dt, iters, X, y, valid_datasets, maxes)\n",
    "    results_arr.append(np.mean(dt_accuracies))\n",
    "    # print(f'dt accuracy: {round(np.mean(dt_accuracies)*100,2)}%')\n",
    "\n",
    "    # AdaBoost\n",
    "    ab = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "    ab_accuracies = train_meta_model(ab, iters, X, y, valid_datasets, maxes)\n",
    "    results_arr.append(np.mean(ab_accuracies))\n",
    "    # print(f'ab accuracy: {round(np.mean(ab_accuracies)*100,2)}%')\n",
    "\n",
    "    # Gradient Boosting\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "    gb_accuracies = train_meta_model(gb, iters, X, y, valid_datasets, maxes)\n",
    "    results_arr.append(np.mean(gb_accuracies))\n",
    "    # print(f'gb accuracy: {round(np.mean(gb_accuracies)*100,2)}%')\n",
    "\n",
    "    # Neural Network\n",
    "    nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "    nn_accuracies = train_meta_model(nn, iters, X, y, valid_datasets, maxes)\n",
    "    results_arr.append(np.mean(nn_accuracies))\n",
    "    # print(f'nn accuracy: {round(np.mean(nn_accuracies)*100,2)}%')\n",
    "\n",
    "    # Bagging\n",
    "    bg = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=0)\n",
    "    bg_accuracies = train_meta_model(bg, iters, X, y, valid_datasets, maxes)\n",
    "    results_arr.append(np.mean(bg_accuracies))\n",
    "    # print(f'bg accuracy: {round(np.mean(bg_accuracies)*100,2)}%')\n",
    "\n",
    "    # Extra Trees\n",
    "    et = ExtraTreesClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=0)\n",
    "    et_accuracies = train_meta_model(et, iters, X, y, valid_datasets, maxes)\n",
    "    results_arr.append(np.mean(et_accuracies))\n",
    "    # print(f'et accuracy: {round(np.mean(et_accuracies)*100,2)}%')\n",
    "\n",
    "    # Voting Classifier\n",
    "    vc = VotingClassifier(estimators=[('rf', rf), ('lr', lr), ('svm', svm), ('knn', knn), ('nb', nb), ('dt', dt), ('ab', ab), ('gb', gb), ('nn', nn), ('bg', bg), ('et', et)], voting='hard')\n",
    "    vc_accuracies = train_meta_model(vc, iters, X, y, valid_datasets, maxes)\n",
    "    results_arr.append(np.mean(vc_accuracies))\n",
    "    # print(f'vc accuracy: {round(np.mean(vc_accuracies)*100,2)}%')\n",
    "\n",
    "    results.append(results_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metadataset</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SVC</th>\n",
       "      <th>KNeighbors</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>MLP</th>\n",
       "      <th>Bagging</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>Voting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concept_metadataset.csv</td>\n",
       "      <td>0.351271</td>\n",
       "      <td>0.332763</td>\n",
       "      <td>0.400492</td>\n",
       "      <td>0.286000</td>\n",
       "      <td>0.282169</td>\n",
       "      <td>0.317627</td>\n",
       "      <td>0.320475</td>\n",
       "      <td>0.270051</td>\n",
       "      <td>0.371559</td>\n",
       "      <td>0.326915</td>\n",
       "      <td>0.346424</td>\n",
       "      <td>0.359085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clustering_metadataset.csv</td>\n",
       "      <td>0.400789</td>\n",
       "      <td>0.359331</td>\n",
       "      <td>0.394930</td>\n",
       "      <td>0.311754</td>\n",
       "      <td>0.204986</td>\n",
       "      <td>0.339563</td>\n",
       "      <td>0.365113</td>\n",
       "      <td>0.318718</td>\n",
       "      <td>0.381683</td>\n",
       "      <td>0.371796</td>\n",
       "      <td>0.384634</td>\n",
       "      <td>0.406070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_metadataset.csv</td>\n",
       "      <td>0.406379</td>\n",
       "      <td>0.270295</td>\n",
       "      <td>0.373720</td>\n",
       "      <td>0.289439</td>\n",
       "      <td>0.242606</td>\n",
       "      <td>0.336886</td>\n",
       "      <td>0.358258</td>\n",
       "      <td>0.303886</td>\n",
       "      <td>0.158152</td>\n",
       "      <td>0.378333</td>\n",
       "      <td>0.423280</td>\n",
       "      <td>0.413955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>general_metadataset.csv</td>\n",
       "      <td>0.430717</td>\n",
       "      <td>0.388476</td>\n",
       "      <td>0.415041</td>\n",
       "      <td>0.333772</td>\n",
       "      <td>0.198407</td>\n",
       "      <td>0.352834</td>\n",
       "      <td>0.320552</td>\n",
       "      <td>0.352607</td>\n",
       "      <td>0.384131</td>\n",
       "      <td>0.379814</td>\n",
       "      <td>0.390455</td>\n",
       "      <td>0.418228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model-based_metadataset.csv</td>\n",
       "      <td>0.411946</td>\n",
       "      <td>0.254585</td>\n",
       "      <td>0.405769</td>\n",
       "      <td>0.274338</td>\n",
       "      <td>0.270223</td>\n",
       "      <td>0.344562</td>\n",
       "      <td>0.373938</td>\n",
       "      <td>0.319038</td>\n",
       "      <td>0.178392</td>\n",
       "      <td>0.382477</td>\n",
       "      <td>0.410738</td>\n",
       "      <td>0.420715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>landmarking_metadataset.csv</td>\n",
       "      <td>0.383639</td>\n",
       "      <td>0.387674</td>\n",
       "      <td>0.383958</td>\n",
       "      <td>0.366007</td>\n",
       "      <td>0.357069</td>\n",
       "      <td>0.336507</td>\n",
       "      <td>0.362410</td>\n",
       "      <td>0.281299</td>\n",
       "      <td>0.383236</td>\n",
       "      <td>0.376542</td>\n",
       "      <td>0.410146</td>\n",
       "      <td>0.408562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>itemset_metadataset.csv</td>\n",
       "      <td>0.368160</td>\n",
       "      <td>0.392556</td>\n",
       "      <td>0.385667</td>\n",
       "      <td>0.307354</td>\n",
       "      <td>0.319271</td>\n",
       "      <td>0.332264</td>\n",
       "      <td>0.250271</td>\n",
       "      <td>0.326917</td>\n",
       "      <td>0.388514</td>\n",
       "      <td>0.335701</td>\n",
       "      <td>0.341389</td>\n",
       "      <td>0.370653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>complexity_metadataset.csv</td>\n",
       "      <td>0.406571</td>\n",
       "      <td>0.250158</td>\n",
       "      <td>0.370444</td>\n",
       "      <td>0.358511</td>\n",
       "      <td>0.223579</td>\n",
       "      <td>0.341977</td>\n",
       "      <td>0.364053</td>\n",
       "      <td>0.358729</td>\n",
       "      <td>0.362436</td>\n",
       "      <td>0.387083</td>\n",
       "      <td>0.412323</td>\n",
       "      <td>0.413917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>info-theory_metadataset.csv</td>\n",
       "      <td>0.391076</td>\n",
       "      <td>0.379545</td>\n",
       "      <td>0.394234</td>\n",
       "      <td>0.298359</td>\n",
       "      <td>0.272538</td>\n",
       "      <td>0.332697</td>\n",
       "      <td>0.337779</td>\n",
       "      <td>0.340545</td>\n",
       "      <td>0.384876</td>\n",
       "      <td>0.366041</td>\n",
       "      <td>0.386193</td>\n",
       "      <td>0.401083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d2v_pretrained_metadaset.csv</td>\n",
       "      <td>0.376028</td>\n",
       "      <td>0.310414</td>\n",
       "      <td>0.373621</td>\n",
       "      <td>0.285517</td>\n",
       "      <td>0.189641</td>\n",
       "      <td>0.290986</td>\n",
       "      <td>0.304124</td>\n",
       "      <td>0.321083</td>\n",
       "      <td>0.164448</td>\n",
       "      <td>0.311028</td>\n",
       "      <td>0.301517</td>\n",
       "      <td>0.350193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>default_metadataset.csv</td>\n",
       "      <td>0.403799</td>\n",
       "      <td>0.271708</td>\n",
       "      <td>0.394562</td>\n",
       "      <td>0.309750</td>\n",
       "      <td>0.236646</td>\n",
       "      <td>0.355042</td>\n",
       "      <td>0.363944</td>\n",
       "      <td>0.324507</td>\n",
       "      <td>0.142604</td>\n",
       "      <td>0.400326</td>\n",
       "      <td>0.444319</td>\n",
       "      <td>0.433979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>statistical_metadataset.csv</td>\n",
       "      <td>0.383510</td>\n",
       "      <td>0.253621</td>\n",
       "      <td>0.380786</td>\n",
       "      <td>0.292510</td>\n",
       "      <td>0.251579</td>\n",
       "      <td>0.313352</td>\n",
       "      <td>0.347476</td>\n",
       "      <td>0.301800</td>\n",
       "      <td>0.228676</td>\n",
       "      <td>0.343110</td>\n",
       "      <td>0.353331</td>\n",
       "      <td>0.380524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>relative_metadataset.csv</td>\n",
       "      <td>0.418472</td>\n",
       "      <td>0.379451</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>0.287653</td>\n",
       "      <td>0.364799</td>\n",
       "      <td>0.305118</td>\n",
       "      <td>0.356146</td>\n",
       "      <td>0.320688</td>\n",
       "      <td>0.372382</td>\n",
       "      <td>0.344826</td>\n",
       "      <td>0.390521</td>\n",
       "      <td>0.418806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metadataset  RandomForest  LogisticRegression       SVC  \\\n",
       "0        concept_metadataset.csv      0.351271            0.332763  0.400492   \n",
       "1     clustering_metadataset.csv      0.400789            0.359331  0.394930   \n",
       "2            all_metadataset.csv      0.406379            0.270295  0.373720   \n",
       "3        general_metadataset.csv      0.430717            0.388476  0.415041   \n",
       "4    model-based_metadataset.csv      0.411946            0.254585  0.405769   \n",
       "5    landmarking_metadataset.csv      0.383639            0.387674  0.383958   \n",
       "6        itemset_metadataset.csv      0.368160            0.392556  0.385667   \n",
       "7     complexity_metadataset.csv      0.406571            0.250158  0.370444   \n",
       "8    info-theory_metadataset.csv      0.391076            0.379545  0.394234   \n",
       "9   d2v_pretrained_metadaset.csv      0.376028            0.310414  0.373621   \n",
       "10       default_metadataset.csv      0.403799            0.271708  0.394562   \n",
       "11   statistical_metadataset.csv      0.383510            0.253621  0.380786   \n",
       "12      relative_metadataset.csv      0.418472            0.379451  0.406576   \n",
       "\n",
       "    KNeighbors  GaussianNB  DecisionTree  AdaBoost  GradientBoosting  \\\n",
       "0     0.286000    0.282169      0.317627  0.320475          0.270051   \n",
       "1     0.311754    0.204986      0.339563  0.365113          0.318718   \n",
       "2     0.289439    0.242606      0.336886  0.358258          0.303886   \n",
       "3     0.333772    0.198407      0.352834  0.320552          0.352607   \n",
       "4     0.274338    0.270223      0.344562  0.373938          0.319038   \n",
       "5     0.366007    0.357069      0.336507  0.362410          0.281299   \n",
       "6     0.307354    0.319271      0.332264  0.250271          0.326917   \n",
       "7     0.358511    0.223579      0.341977  0.364053          0.358729   \n",
       "8     0.298359    0.272538      0.332697  0.337779          0.340545   \n",
       "9     0.285517    0.189641      0.290986  0.304124          0.321083   \n",
       "10    0.309750    0.236646      0.355042  0.363944          0.324507   \n",
       "11    0.292510    0.251579      0.313352  0.347476          0.301800   \n",
       "12    0.287653    0.364799      0.305118  0.356146          0.320688   \n",
       "\n",
       "         MLP   Bagging  ExtraTrees    Voting  \n",
       "0   0.371559  0.326915    0.346424  0.359085  \n",
       "1   0.381683  0.371796    0.384634  0.406070  \n",
       "2   0.158152  0.378333    0.423280  0.413955  \n",
       "3   0.384131  0.379814    0.390455  0.418228  \n",
       "4   0.178392  0.382477    0.410738  0.420715  \n",
       "5   0.383236  0.376542    0.410146  0.408562  \n",
       "6   0.388514  0.335701    0.341389  0.370653  \n",
       "7   0.362436  0.387083    0.412323  0.413917  \n",
       "8   0.384876  0.366041    0.386193  0.401083  \n",
       "9   0.164448  0.311028    0.301517  0.350193  \n",
       "10  0.142604  0.400326    0.444319  0.433979  \n",
       "11  0.228676  0.343110    0.353331  0.380524  \n",
       "12  0.372382  0.344826    0.390521  0.418806  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\"Metadataset\", \"RandomForest\", \"LogisticRegression\", \"SVC\", \"KNeighbors\",\n",
    "          \"GaussianNB\", \"DecisionTree\", \"AdaBoost\", \"GradientBoosting\",\n",
    "          \"MLP\", \"Bagging\", \"ExtraTrees\",  \"Voting\"]\n",
    "\n",
    "df = pd.DataFrame(results, columns=models)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a6bfd8c3de063d8a2db39dcc235169c19bbfd469ccbe944bac6502075c207d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
